import{_ as k,o as z,c as A,b as s,d as t,e as a,w as l,a as y,r as c}from"./chunks/framework.882288bf.js";const ga=JSON.parse('{"title":"多层感知机","description":"","frontmatter":{"layout":"doc","title":"多层感知机","createTime":"2023/3/26","preview":"我们将第一次介绍真正的深度网络。 最简单的深度网络称为多层感知机。"},"headers":[],"relativePath":"algorithm/多层感知机.md","lastUpdated":1679934595000}'),F={name:"algorithm/多层感知机.md"},L=y('<h1 id="多层感知机" tabindex="-1">多层感知机 <a class="header-anchor" href="#多层感知机" aria-label="Permalink to &quot;多层感知机&quot;">​</a></h1><blockquote><p>最简单的深度网络称为<em>多层感知机</em>。多层感知机由多层神经元组成， 每一层与它的上一层相连，从中接收输入； 同时每一层也与它的下一层相连，影响当前层的神经元。 当我们训练容量较大的模型时，我们面临着<em>过拟合</em>的风险。 因此，本章将从基本的概念介绍开始讲起，包括<em>过拟合</em>、<em>欠拟合</em>和模型选择。 为了解决这些问题，本章将介绍<em>权重衰减</em>和<em>暂退法</em>等正则化技术。 我们还将讨论数值稳定性和参数初始化相关的问题， 这些问题是成功训练深度网络的关键。</p></blockquote><h2 id="隐藏层" tabindex="-1">隐藏层 <a class="header-anchor" href="#隐藏层" aria-label="Permalink to &quot;隐藏层&quot;">​</a></h2><blockquote><p>仿射变换中的<em>线性</em>是一个很强的假设。</p></blockquote><p>每一层都输出到上面的层，直到生成最后的输出。 我们可以把前L−1层看作表示，把最后一层看作线性预测器。 这种架构通常称为<em>多层感知机</em>（multilayer perceptron），通常缩写为<em>MLP</em>。</p><p><img src="https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230326202929640.png" alt="image-20230326202929640"></p>',6),M=s("em",null,[s("strong",null,"对每个隐藏单元应用非线性的激活函数（activation function）σ。 激活函数的输出（例如，σ(⋅)）被称为活性值（activations）。")],-1),q={class:"katex-display"},T={class:"katex"},P={class:"katex-mathml"},R=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3.196em","vertical-align":"-1.348em"}}),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-r"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.848em"}},[s("span",{style:{top:"-3.848em"}},[s("span",{class:"pstrut",style:{height:"2.938em"}}),s("span",{class:"mord"})]),s("span",{style:{top:"-2.25em"}},[s("span",{class:"pstrut",style:{height:"2.938em"}}),s("span",{class:"mord"})])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.348em"}},[s("span")])])])]),s("span",{class:"col-align-l"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.848em"}},[s("span",{style:{top:"-3.91em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mord mathbf"},"H"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"σ"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathbf"},"X"),s("span",{class:"mord"},[s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"W"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mtight"},"1"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathbf"},"b"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mtight"},"1"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-2.312em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"mord mathbf"},"O"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"HW"),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mtight"},"2"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathbf"},"b"),s("span",{class:"mord"},[s("span",{class:"mord"}),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mtight"},"2"),s("span",{class:"mclose mtight"},")")])])])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.348em"}},[s("span")])])])])])])])],-1),D=y('<blockquote><p>通用近似定理：</p><p>多层感知机可以通过隐藏神经元，捕捉到输入之间复杂的相互作用， 这些神经元依赖于每个输入的值。</p><p>事实上，通过使用更深（而不是更广）的网络，我们可以更容易地逼近许多函数。</p></blockquote><h2 id="激活函数" tabindex="-1">激活函数 <a class="header-anchor" href="#激活函数" aria-label="Permalink to &quot;激活函数&quot;">​</a></h2><p>激活函数是一种在神经网络中广泛使用的非线性函数，用于将神经网络中的输入信号进行变换，并输出给下一层神经元或输出层。</p><p>通常情况下，激活函数应该满足以下几个条件：</p><ol><li><strong>非线性</strong>：激活函数应该是非线性的，能够引入更多的非线性因素，从而提高网络的表达能力。</li><li><strong>可导</strong>：激活函数应该是可导的，这样可以方便地使用梯度下降等优化算法进行网络训练。</li><li><strong>单调性</strong>：激活函数应该具有单调性，这样可以保证网络训练过程中的误差函数具有唯一最小值，从而提高训练效果。</li><li><strong>有界性</strong>：激活函数应该具有有界性，这样可以防止梯度爆炸或消失等问题，从而保证网络的稳定性。</li></ol><h3 id="relu" tabindex="-1">ReLU <a class="header-anchor" href="#relu" aria-label="Permalink to &quot;ReLU&quot;">​</a></h3><p>最受欢迎的激活函数是<code>修正线性单元（Rectified linear unit，ReLU）</code>， 因为它实现简单，同时在各种预测任务中表现良好。</p><p>给定元素x，ReLU函数被定义为该元素与0的最大值：</p>',8),C={class:"katex-display"},E={class:"katex"},S={class:"katex-mathml"},U=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"LU")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},"max"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},"0"),s("span",{class:"mclose"},")")])],-1),V=s("p",null,[s("img",{src:"https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230327121552478.png",alt:"image-20230327121552478"})],-1),I=s("p",null,"导数：",-1),N=s("ul",null,[s("li",null,"输入为负：导数为 0"),s("li",null,"输入为正：导数为 1"),s("li",null,"输入为 0：导数不存在，默认使用左侧导数")],-1),H=s("p",null,[s("img",{src:"https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230327122153580.png",alt:"image-20230327122153580"})],-1),W=s("blockquote",null,[s("p",null,"使用ReLU的原因是，它求导表现得特别好：要么让参数消失，要么让参数通过。 这使得优化表现得更好，并且ReLU减轻了困扰以往神经网络的梯度消失问题（稍后将详细介绍）。")],-1),$=s("em",null,"参数化ReLU",-1),X=s("em",null,"pReLU",-1),O=s("a",{href:"https://zh.d2l.ai/chapter_references/zreferences.html#id59",target:"_blank",rel:"noreferrer"},[t("He "),s("em",null,"et al."),t(", 2015")],-1),j={class:"katex-display"},J={class:"katex"},G={class:"katex-mathml"},K=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"pReLU")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},"max"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.0037em"}},"α"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},"min"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"0"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])],-1),Q=s("h3",{id:"sigmoid",tabindex:"-1"},[t("Sigmoid "),s("a",{class:"header-anchor",href:"#sigmoid","aria-label":'Permalink to "Sigmoid"'},"​")],-1),Y=s("em",null,"sigmoid函数",-1),Z=s("code",null,"sigmoid",-1),ss=s("code",null,"挤压函数（squashing function）",-1),as={class:"katex-display"},ls={class:"katex"},ts={class:"katex-mathml"},es=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"sigmod")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.2574em","vertical-align":"-0.936em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mop"},"exp"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.936em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])],-1),ns=s("p",null,[s("img",{src:"https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230327123011469.png",alt:"image-20230327123011469"})],-1),ps={class:"katex-display"},ms={class:"katex"},cs={class:"katex-mathml"},is=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.0574em","vertical-align":"-0.686em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mord mathnormal"},"x")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mord text"},[s("span",{class:"mord"},"signoid")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.363em","vertical-align":"-0.936em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.427em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mop"},"exp"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mclose"},[s("span",{class:"mclose"},")"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7401em"}},[s("span",{style:{top:"-2.989em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mop"},"exp"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.936em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"signoid")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"sigmod")]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mclose delimcenter",style:{top:"0em"}},")")])])],-1),rs=s("img",{src:"https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230327123549840.png",alt:"image-20230327123549840"},null,-1),os=s("h3",{id:"tanh",tabindex:"-1"},[t("Tanh "),s("a",{class:"header-anchor",href:"#tanh","aria-label":'Permalink to "Tanh"'},"​")],-1),us=s("code",null,"sigmoid",-1),ds=s("code",null,"tanh(双曲正切)",-1),hs=s("code",null,"tanh",-1),_s={class:"katex-display"},gs={class:"katex"},fs={class:"katex-mathml"},ys=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},"tanh"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.363em","vertical-align":"-0.936em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.427em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mop"},"exp"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"2"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mop"},"exp"),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"−"),s("span",{class:"mord"},"2"),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.936em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])],-1),vs=s("code",null,"tanh",-1),bs=s("code",null,"sigmoid",-1),xs=s("code",null,"tanh",-1),ws=s("p",null,[s("img",{src:"https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230327123857670.png",alt:"image-20230327123857670"})],-1),Bs={class:"katex-display"},ks={class:"katex"},zs={class:"katex-mathml"},As=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.0574em","vertical-align":"-0.686em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d"),s("span",{class:"mord mathnormal"},"x")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"d")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop"},"tanh"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7278em","vertical-align":"-0.0833em"}}),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.1484em","vertical-align":"-0.25em"}}),s("span",{class:"mop"},[s("span",{class:"mop"},"tanh"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8984em"}},[s("span",{style:{top:"-3.1473em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"x"),s("span",{class:"mclose"},")")])],-1),Fs=s("img",{src:"https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230327124154784.png",alt:"image-20230327124154784"},null,-1),Ls=y('<h2 id="模型选择、欠拟合、过拟合" tabindex="-1">模型选择、欠拟合、过拟合 <a class="header-anchor" href="#模型选择、欠拟合、过拟合" aria-label="Permalink to &quot;模型选择、欠拟合、过拟合&quot;">​</a></h2><blockquote><p>将模型在训练数据上拟合的比在潜在分布中更接近的现象称为<code>过拟合（overfitting）</code>， 用于对抗过拟合的技术称为<code>正则化（regularization）</code>。</p></blockquote><h2 id="权重衰减" tabindex="-1">权重衰减 <a class="header-anchor" href="#权重衰减" aria-label="Permalink to &quot;权重衰减&quot;">​</a></h2><p>在训练参数化机器学习模型时， <em>权重衰减</em>（weight decay）是最广泛使用的正则化的技术之一， 它通常也被称为L2<em>正则化</em>。</p>',4),Ms={class:"katex"},qs={class:"katex-mathml"},Ts=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathbf"},"x"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8491em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8491em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"⊤")])])])])])])])]),s("span",{class:"mord mathbf"},"x")])],-1),Ps=s("em",null,"最小化训练标签上的预测损失",-1),Rs=s("em",null,"最小化预测损失和惩罚项之和",-1),Ds=s("p",null,[t("L2正则化线性模型构成经典的"),s("em",null,"岭回归"),t("（ridge regression）算法， L1正则化线性回归是统计学中类似的基本模型， 通常被称为"),s("em",null,"套索回归"),t("（lasso regression）。 使用L2范数的一个原因是它对权重向量的大分量施加了巨大的惩罚。 这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。 在实践中，这可能使它们对单个变量中的观测误差更为稳定。 相比之下，L1惩罚会导致模型将权重集中在一小部分特征上， 而将其他权重清除为零。 这称为"),s("em",null,"特征选择"),t("（feature selection），这可能是其他场景下需要的。")],-1),Cs=s("p",null,"例子：",-1),Es={class:"katex-display"},Ss={class:"katex"},Us={class:"katex-mathml"},Vs=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"w"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9291em","vertical-align":"-1.2777em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"n")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"2")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mord"},[s("span",{class:"delimsizing size2"},"(")]),s("span",{class:"mord"},[s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"w"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"⊤")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathbf"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7778em","vertical-align":"-0.0833em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.004em","vertical-align":"-0.65em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"delimsizing size2"},")")]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.354em"}},[s("span",{style:{top:"-3.6029em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])],-1),Is=s("em",null,"正则化常数",-1),Ns=s("code",null,"λ",-1),Hs={class:"katex-display"},Ws={class:"katex"},$s={class:"katex-mathml"},Xs=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"L"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"w"),s("span",{class:"mpunct"},","),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.0574em","vertical-align":"-0.686em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3714em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"2")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"λ")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mord"},"∥"),s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"w"),s("span",{class:"mord"},[s("span",{class:"mord"},"∥"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])])],-1),Os={class:"katex-display"},js={class:"katex"},Js={class:"katex-mathml"},Gs=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"w")]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"←"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mopen"},"("),s("span",{class:"mord"},"1"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"η"),s("span",{class:"mord mathnormal"},"λ"),s("span",{class:"mclose"},")"),s("span",{class:"mord text"},[s("span",{class:"mord"},"w")]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.4717em","vertical-align":"-1.3217em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.1076em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"∣"),s("span",{class:"mord mathcal",style:{"margin-right":"0.03041em"}},"B"),s("span",{class:"mord"},"∣")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"η")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.936em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.05em"}},[s("span",{style:{top:"-1.8557em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"∈"),s("span",{class:"mord mathcal mtight",style:{"margin-right":"0.03041em"}},"B")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3217em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},"(")]),s("span",{class:"mord"},[s("span",{class:"mord text"},[s("span",{class:"mord"},"w")]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"⊤")])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathbf"},"x"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal"},"b"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"−"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"y"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.938em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mopen mtight"},"("),s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mclose mtight"},")")])])])])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},")")])])])],-1),Ks=s("em",null,"权重衰减",-1),Qs=s("em",null,"衰减",-1),Ys=y('<p>是否对相应的偏置b<sup>2</sup>进行惩罚在不同的实践中会有所不同， 在神经网络的不同层中也会有所不同。 通常，网络输出层的偏置项不会被正则化。</p><h2 id="暂退法-dropout" tabindex="-1">暂退法 - Dropout <a class="header-anchor" href="#暂退法-dropout" aria-label="Permalink to &quot;暂退法 - Dropout&quot;">​</a></h2><p>泛化性和灵活性之间的这种基本权衡被描述为<code>偏差-方差权衡（bias-variance tradeoff）</code>。 线性模型有很高的偏差：它们只能表示一小类函数。 然而，这些模型的方差很低：它们在不同的随机数据样本上可以得出相似的结果。</p><p>经典泛化理论认为，为了缩小训练和测试性能之间的差距，应该以简单的模型为目标。</p><ul><li><p>简单性以较小维度的形式展现， 我们在 <a href="https://zh.d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html#sec-model-selection" target="_blank" rel="noreferrer">4.4节</a> 讨论线性模型的单项式函数时探讨了这一点。 此外，正如我们在<a href="https://zh.d2l.ai/chapter_multilayer-perceptrons/weight-decay.html#sec-weight-decay" target="_blank" rel="noreferrer">4.5节</a> 中讨论权重衰减（L2正则化）时看到的那样， 参数的范数也代表了一种有用的简单性度量。</p></li><li><p>简单性的另一个角度是平滑性，即函数不应该对其输入的微小变化敏感。</p><blockquote><p>有人提出了一个想法： 在训练过程中，他们建议在计算后续层之前向网络的每一层注入噪声。 因为当训练一个有多层的深层网络时，注入噪声只会在输入-输出映射上增强平滑性。</p></blockquote><p>这个想法被称为<em>暂退法</em>（dropout）。 暂退法在前向传播过程中，计算每一内部层的同时注入噪声，这已经成为训练神经网络的常用技术。</p><blockquote><p>暂退法的原始论文提到了一个关于有性繁殖的类比： 神经网络过拟合与每一层都依赖于前一层激活值相关，称这种情况为“共适应性”。 作者认为，暂退法会破坏共适应性，就像有性生殖会破坏共适应的基因一样。</p></blockquote></li></ul><p>如何注入噪声：一种想法是以一种<em>无偏向</em>（unbiased）的方式注入噪声。 这样在固定住其他层时，<em><strong>每一层的期望值等于没有噪音时的值</strong></em>。</p>',6),Zs=s("code",null,"h",-1),sa=s("em",null,"暂退概率",-1),aa=s("code",null,"p",-1),la=s("code",null,"h′",-1),ta={class:"katex-display"},ea={class:"katex"},na={class:"katex-mathml"},pa=s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal"},"h"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.5612em","vertical-align":"-1.0306em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size3"},"{")]),s("span",{class:"mord"},[s("span",{class:"mtable"},[s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.5306em"}},[s("span",{style:{top:"-3.6906em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"0")])]),s("span",{style:{top:"-2.4505em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8801em"}},[s("span",{style:{top:"-2.655em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"1"),s("span",{class:"mbin mtight"},"−"),s("span",{class:"mord mathnormal mtight"},"p")])])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.394em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"h")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.4811em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.0306em"}},[s("span")])])])]),s("span",{class:"arraycolsep",style:{width:"0.5em"}}),s("span",{class:"arraycolsep",style:{width:"0.5em"}}),s("span",{class:"col-align-c"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.5306em"}},[s("span",{style:{top:"-3.6906em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P")])]),s("span",{style:{top:"-2.4505em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},[s("span",{class:"mord mathrm"},"other")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.0306em"}},[s("span")])])])])])]),s("span",{class:"mclose nulldelimiter"})])])],-1),ma=y(`<p><strong>通常，我们在测试时不用暂退法。</strong> 给定一个训练好的模型和一个新的样本，我们不会丢弃任何节点，因此不需要标准化。 然而也有一些例外：一些研究人员在测试时使用暂退法， 用于估计神经网络预测的“不确定性”： 如果通过许多不同的暂退法遮盖后得到的预测结果都是一致的，那么我们可以说网络发挥更稳定。</p><blockquote><p>PyTorch 中<code>nn.Dropout</code>默认在<code>train()</code>时生效，<code>eval()</code>不生效，若想在验证时生效，可手动开启：</p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki one-dark-pro vp-code-dark"><code><span class="line"><span style="color:#ABB2BF;">net.</span><span style="color:#61AFEF;">eval</span><span style="color:#ABB2BF;">()</span></span>
<span class="line"><span style="color:#C678DD;">def</span><span style="color:#ABB2BF;"> </span><span style="color:#61AFEF;">enable_dropout</span><span style="color:#ABB2BF;">(</span><span style="color:#D19A66;font-style:italic;">m</span><span style="color:#ABB2BF;">):</span></span>
<span class="line"><span style="color:#ABB2BF;">  </span><span style="color:#C678DD;font-style:italic;">if</span><span style="color:#ABB2BF;"> </span><span style="color:#56B6C2;">isinstance</span><span style="color:#ABB2BF;">(m, nn.Dropout):</span></span>
<span class="line"><span style="color:#ABB2BF;">    m.</span><span style="color:#61AFEF;">train</span><span style="color:#ABB2BF;">()		</span><span style="color:#7F848E;font-style:italic;"># 手动开启 Dropout 的训练模式，就可以生效了</span></span>
<span class="line"><span style="color:#ABB2BF;">net.</span><span style="color:#61AFEF;">apply</span><span style="color:#ABB2BF;">(enable_dropout)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;">y </span><span style="color:#56B6C2;">=</span><span style="color:#ABB2BF;"> </span><span style="color:#61AFEF;">net</span><span style="color:#ABB2BF;">(X)	</span><span style="color:#7F848E;font-style:italic;"># 正常运行即可</span></span>
<span class="line"></span></code></pre><pre class="shiki one-dark-pro vp-code-light"><code><span class="line"><span style="color:#ABB2BF;">net.</span><span style="color:#61AFEF;">eval</span><span style="color:#ABB2BF;">()</span></span>
<span class="line"><span style="color:#C678DD;">def</span><span style="color:#ABB2BF;"> </span><span style="color:#61AFEF;">enable_dropout</span><span style="color:#ABB2BF;">(</span><span style="color:#D19A66;font-style:italic;">m</span><span style="color:#ABB2BF;">):</span></span>
<span class="line"><span style="color:#ABB2BF;">  </span><span style="color:#C678DD;font-style:italic;">if</span><span style="color:#ABB2BF;"> </span><span style="color:#56B6C2;">isinstance</span><span style="color:#ABB2BF;">(m, nn.Dropout):</span></span>
<span class="line"><span style="color:#ABB2BF;">    m.</span><span style="color:#61AFEF;">train</span><span style="color:#ABB2BF;">()		</span><span style="color:#7F848E;font-style:italic;"># 手动开启 Dropout 的训练模式，就可以生效了</span></span>
<span class="line"><span style="color:#ABB2BF;">net.</span><span style="color:#61AFEF;">apply</span><span style="color:#ABB2BF;">(enable_dropout)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#ABB2BF;">y </span><span style="color:#56B6C2;">=</span><span style="color:#ABB2BF;"> </span><span style="color:#61AFEF;">net</span><span style="color:#ABB2BF;">(X)	</span><span style="color:#7F848E;font-style:italic;"># 正常运行即可</span></span>
<span class="line"></span></code></pre></div></blockquote><blockquote><p>除了标准暂退法技术的方法，我们可以考虑一些其他的正则化方法，比如<code>噪声注入（Noise Injection）</code>。</p><p>噪声注入是一种在深度学习中应用广泛的正则化方法，<strong>可以通过向输入数据、权重或激活值中注入随机噪声</strong>来增加模型的鲁棒性，从而提高泛化能力。</p></blockquote>`,3);function ca(ia,ra,oa,ua,da,ha){const p=c("mrow"),_=c("mstyle"),g=c("mtd"),n=c("mi"),e=c("mo"),m=c("mn"),i=c("msup"),v=c("mtr"),b=c("mtable"),r=c("annotation"),o=c("semantics"),u=c("math"),d=c("eqn"),f=c("mtext"),h=c("mfrac"),x=c("eq"),w=c("munderover"),B=c("munder");return z(),A("div",null,[L,s("p",null,[t("为了发挥多层架构的潜力， 我们还需要一个额外的关键要素： 在仿射变换之后"),M,t(" 一般来说，有了激活函数，就不可能再将我们的多层感知机退化成线性模型： "),s("section",null,[a(d,null,{default:l(()=>[s("span",q,[s("span",T,[s("span",P,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(b,{rowspacing:"0.25em",columnalign:"right left",columnspacing:"0em"},{default:l(()=>[a(v,null,{default:l(()=>[a(g,null,{default:l(()=>[a(_,{scriptlevel:"0",displaystyle:"true"},{default:l(()=>[a(p)]),_:1})]),_:1}),a(g,null,{default:l(()=>[a(_,{scriptlevel:"0",displaystyle:"true"},{default:l(()=>[a(p,null,{default:l(()=>[a(p),a(n,{mathvariant:"bold"},{default:l(()=>[t("H")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(n,null,{default:l(()=>[t("σ")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("X")]),_:1}),a(i,null,{default:l(()=>[a(n,{mathvariant:"bold"},{default:l(()=>[t("W")]),_:1}),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(i,null,{default:l(()=>[a(n,{mathvariant:"bold"},{default:l(()=>[t("b")]),_:1}),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1})]),_:1})]),_:1}),a(v,null,{default:l(()=>[a(g,null,{default:l(()=>[a(_,{scriptlevel:"0",displaystyle:"true"},{default:l(()=>[a(p)]),_:1})]),_:1}),a(g,null,{default:l(()=>[a(_,{scriptlevel:"0",displaystyle:"true"},{default:l(()=>[a(p,null,{default:l(()=>[a(p),a(n,{mathvariant:"bold"},{default:l(()=>[t("O")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("H")]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("W")]),_:1}),a(i,null,{default:l(()=>[a(p),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("b")]),_:1}),a(i,null,{default:l(()=>[a(p),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1})]),_:1})]),_:1})]),_:1})]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" \\begin{aligned}&\\mathbf{H}=\\sigma(\\mathbf{X}\\mathbf{W}^{(1)}+\\mathbf{b}^{(1)})\\\\ &\\mathbf{O}=\\mathbf{H}\\mathbf{W}{}^{(2)}+\\mathbf{b}{}^{(2)}\\end{aligned} ")]),_:1})]),_:1})]),_:1})]),R])])]),_:1})])]),D,s("section",null,[a(d,null,{default:l(()=>[s("span",C,[s("span",E,[s("span",S,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("R")]),_:1}),a(n,null,{default:l(()=>[t("e")]),_:1}),a(n,null,{default:l(()=>[t("L")]),_:1}),a(n,null,{default:l(()=>[t("U")]),_:1})]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(n,null,{default:l(()=>[t("max")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{separator:"true"},{default:l(()=>[t(",")]),_:1}),a(m,null,{default:l(()=>[t("0")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" {ReLU}(x)=\\max(x,0) ")]),_:1})]),_:1})]),_:1})]),U])])]),_:1})]),V,I,N,H,W,s("blockquote",null,[s("p",null,[t("注意，ReLU函数有许多变体，包括"),$,t("（Parameterized ReLU，"),X,t("） 函数 ("),O,t(")。 该变体为ReLU添加了一个线性项，因此即使参数是负的，某些信息仍然可以通过： "),s("section",null,[a(d,null,{default:l(()=>[s("span",j,[s("span",J,[s("span",G,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(f,null,{default:l(()=>[t("pReLU")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(n,null,{default:l(()=>[t("max")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("0")]),_:1}),a(e,{separator:"true"},{default:l(()=>[t(",")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(n,null,{default:l(()=>[t("α")]),_:1}),a(n,null,{default:l(()=>[t("min")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("0")]),_:1}),a(e,{separator:"true"},{default:l(()=>[t(",")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" \\text{pReLU}(x)=\\max(0,x)+\\alpha\\min(0,x) ")]),_:1})]),_:1})]),_:1})]),K])])]),_:1})])])]),Q,s("p",null,[t("对于一个定义域在R中的输入， "),Y,t("将输入变换为区间(0, 1)上的输出。 因此，"),Z,t("通常称为"),ss,t("：它将范围（-inf, inf）中的任意输入压缩到区间（0, 1）中的某个值： "),s("section",null,[a(d,null,{default:l(()=>[s("span",as,[s("span",ls,[s("span",ts,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(f,null,{default:l(()=>[t("sigmod")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(h,null,{default:l(()=>[a(m,null,{default:l(()=>[t("1")]),_:1}),a(p,null,{default:l(()=>[a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(n,null,{default:l(()=>[t("exp")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" \\text{sigmod}(x)=\\dfrac{1}{1+\\exp(-x)} ")]),_:1})]),_:1})]),_:1})]),es])])]),_:1})]),t(" 它是一个平滑的、可微的阈值单元近似。")]),ns,s("p",null,[t("导数： "),s("section",null,[a(d,null,{default:l(()=>[s("span",ps,[s("span",ms,[s("span",cs,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(h,null,{default:l(()=>[a(n,null,{default:l(()=>[t("d")]),_:1}),a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("d")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1})]),_:1})]),_:1}),a(f,null,{default:l(()=>[t("signoid")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(h,null,{default:l(()=>[a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("exp")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1}),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(n,null,{default:l(()=>[t("exp")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(i,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1})]),_:1})]),_:1})]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(f,null,{default:l(()=>[t("signoid")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(p,null,{default:l(()=>[a(e,{fence:"true"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(f,null,{default:l(()=>[t("sigmod")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,{fence:"true"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" \\dfrac{d}{dx}\\text{signoid}(x)=\\dfrac{\\exp(-x)}{(1+\\exp(-x))^2}=\\text{signoid}(x)\\left(1-\\text{sigmod}(x)\\right) ")]),_:1})]),_:1})]),_:1})]),is])])]),_:1})]),rs]),os,s("p",null,[t("与"),us,t("函数类似， "),ds,t("函数也能将其输入压缩转换到区间(-1, 1)上。 "),hs,t("函数的公式如下： "),s("section",null,[a(d,null,{default:l(()=>[s("span",_s,[s("span",gs,[s("span",fs,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("tanh")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(h,null,{default:l(()=>[a(p,null,{default:l(()=>[a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(n,null,{default:l(()=>[t("exp")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1}),a(p,null,{default:l(()=>[a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(n,null,{default:l(()=>[t("exp")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" \\tanh(x)=\\dfrac{1-\\exp(-2x)}{1+\\exp(-2x)} ")]),_:1})]),_:1})]),_:1})]),ys])])]),_:1})]),t(" 注意，当输入在0附近时，"),vs,t("函数接近线性变换。 函数的形状类似于"),bs,t("函数， 不同的是"),xs,t("函数关于坐标系原点中心对称。")]),ws,s("p",null,[t("导数： "),s("section",null,[a(d,null,{default:l(()=>[s("span",Bs,[s("span",ks,[s("span",zs,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(h,null,{default:l(()=>[a(n,null,{default:l(()=>[t("d")]),_:1}),a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("d")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1})]),_:1})]),_:1}),a(n,null,{default:l(()=>[t("tanh")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(i,null,{default:l(()=>[a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("tanh")]),_:1}),a(e,null,{default:l(()=>[t("⁡")]),_:1})]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1})]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" \\dfrac{d}{dx}\\tanh(x)=1-\\tanh^2(x) ")]),_:1})]),_:1})]),_:1})]),As])])]),_:1})]),Fs]),Ls,s("p",null,[t("一种简单的方法是通过线性函数 "),a(x,null,{default:l(()=>[s("span",Ms,[s("span",qs,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("f")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("x")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(i,null,{default:l(()=>[a(n,{mathvariant:"bold"},{default:l(()=>[t("w")]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("⊤")]),_:1})]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("x")]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t("f(\\mathbf{x})=\\mathbf{w}^{\\top}\\mathbf{x}")]),_:1})]),_:1})]),_:1})]),Ts])]),_:1}),t(" 中的权重向量的某个范数来度量其复杂性。要保证权重向量比较小， 最常用方法是将其范数作为惩罚项加到最小化损失的问题中。 将原来的训练目标"),Ps,t("， 调整为"),Rs,t("。")]),Ds,Cs,s("p",null,[t("在线性回归中，我们的损失是： "),s("section",null,[a(d,null,{default:l(()=>[s("span",Es,[s("span",Ss,[s("span",Us,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("L")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("w")]),_:1}),a(e,{separator:"true"},{default:l(()=>[t(",")]),_:1}),a(n,null,{default:l(()=>[t("b")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(h,null,{default:l(()=>[a(m,null,{default:l(()=>[t("1")]),_:1}),a(n,null,{default:l(()=>[t("n")]),_:1})]),_:1}),a(w,null,{default:l(()=>[a(e,null,{default:l(()=>[t("∑")]),_:1}),a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("i")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(m,null,{default:l(()=>[t("1")]),_:1})]),_:1}),a(n,null,{default:l(()=>[t("n")]),_:1})]),_:1}),a(h,null,{default:l(()=>[a(m,null,{default:l(()=>[t("1")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1})]),_:1}),a(e,{fence:"false",stretchy:"true",minsize:"1.8em",maxsize:"1.8em"},{default:l(()=>[t("(")]),_:1}),a(i,null,{default:l(()=>[a(n,{mathvariant:"bold"},{default:l(()=>[t("w")]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("⊤")]),_:1})]),_:1}),a(i,null,{default:l(()=>[a(n,{mathvariant:"bold"},{default:l(()=>[t("x")]),_:1}),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("i")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(n,null,{default:l(()=>[t("b")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(i,null,{default:l(()=>[a(n,null,{default:l(()=>[t("y")]),_:1}),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("i")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(i,null,{default:l(()=>[a(e,{fence:"false",stretchy:"true",minsize:"1.8em",maxsize:"1.8em"},{default:l(()=>[t(")")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1})]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" L(\\mathbf{w},b)=\\dfrac{1}{n}\\sum_{i=1}^n\\dfrac{1}{2}\\Big(\\mathbf{w}^\\top\\mathbf{x}^{(i)}+b-y^{(i)}\\Big)^2 ")]),_:1})]),_:1})]),_:1})]),Vs])])]),_:1})]),t(" 我们通过"),Is,Ns,t("来平衡这个新的额外惩罚， 这是一个非负超参数，我们使用验证数据拟合： "),s("section",null,[a(d,null,{default:l(()=>[s("span",Hs,[s("span",Ws,[s("span",$s,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("L")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("w")]),_:1}),a(e,{separator:"true"},{default:l(()=>[t(",")]),_:1}),a(n,null,{default:l(()=>[t("b")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(h,null,{default:l(()=>[a(n,null,{default:l(()=>[t("λ")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1})]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("∥")]),_:1}),a(n,{mathvariant:"bold"},{default:l(()=>[t("w")]),_:1}),a(i,null,{default:l(()=>[a(n,{mathvariant:"normal"},{default:l(()=>[t("∥")]),_:1}),a(m,null,{default:l(()=>[t("2")]),_:1})]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" L(\\mathbf{w},b)+\\dfrac{\\lambda}{2}\\|\\mathbf{w}\\|^2 ")]),_:1})]),_:1})]),_:1})]),Xs])])]),_:1})]),t(" L2正则化回归的小批量随机梯度下降更新如下式： "),s("section",null,[a(d,null,{default:l(()=>[s("span",Os,[s("span",js,[s("span",Js,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(f,null,{default:l(()=>[t("w")]),_:1}),a(e,null,{default:l(()=>[t("←")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(n,null,{default:l(()=>[t("η")]),_:1}),a(n,null,{default:l(()=>[t("λ")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1}),a(f,null,{default:l(()=>[t("w")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(h,null,{default:l(()=>[a(n,null,{default:l(()=>[t("η")]),_:1}),a(p,null,{default:l(()=>[a(n,{mathvariant:"normal"},{default:l(()=>[t("∣")]),_:1}),a(n,{mathvariant:"script"},{default:l(()=>[t("B")]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("∣")]),_:1})]),_:1})]),_:1}),a(B,null,{default:l(()=>[a(e,null,{default:l(()=>[t("∑")]),_:1}),a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("i")]),_:1}),a(e,null,{default:l(()=>[t("∈")]),_:1}),a(n,{mathvariant:"script"},{default:l(()=>[t("B")]),_:1})]),_:1})]),_:1}),a(i,null,{default:l(()=>[a(n,{mathvariant:"double-struck"},{default:l(()=>[t("x")]),_:1}),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("i")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(p,null,{default:l(()=>[a(e,{fence:"true"},{default:l(()=>[t("(")]),_:1}),a(i,null,{default:l(()=>[a(f,null,{default:l(()=>[t("w")]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("⊤")]),_:1})]),_:1}),a(i,null,{default:l(()=>[a(n,{mathvariant:"bold"},{default:l(()=>[t("x")]),_:1}),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("i")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(e,null,{default:l(()=>[t("+")]),_:1}),a(n,null,{default:l(()=>[t("b")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(i,null,{default:l(()=>[a(n,null,{default:l(()=>[t("y")]),_:1}),a(p,null,{default:l(()=>[a(e,{stretchy:"false"},{default:l(()=>[t("(")]),_:1}),a(n,null,{default:l(()=>[t("i")]),_:1}),a(e,{stretchy:"false"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(e,{fence:"true"},{default:l(()=>[t(")")]),_:1})]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" \\text{w}\\leftarrow(1-\\eta\\lambda)\\text{w}-\\dfrac{\\eta}{|\\mathcal{B}|}\\sum\\limits_{i\\in\\mathcal{B}}\\mathbb{x}^{(i)}\\left(\\text{w}^\\top\\mathbf{x}^{(i)}+b-y^{(i)}\\right) ")]),_:1})]),_:1})]),_:1})]),Gs])])]),_:1})]),t(" 我们根据估计值与观测值之间的差异来更新w。 然而，我们同时也在试图将w的大小缩小到零。 这就是为什么这种方法有时被称为"),Ks,t("。 我们仅考虑惩罚项，优化算法在训练的每一步"),Qs,t("权重。 与特征选择相比，权重衰减为我们提供了一种连续的机制来调整函数的复杂度。 较小的λ值对应较少约束的w， 而较大的λ值对w的约束更大。")]),Ys,s("p",null,[t("在标准暂退法正则化中，通过按保留（未丢弃）的节点的分数进行规范化来消除每一层的偏差。 换言之，每个中间活性值"),Zs,t("以"),sa,aa,t("由随机变量"),la,t("替换，如下所示： "),s("section",null,[a(d,null,{default:l(()=>[s("span",ta,[s("span",ea,[s("span",na,[a(u,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},{default:l(()=>[a(o,null,{default:l(()=>[a(p,null,{default:l(()=>[a(n,null,{default:l(()=>[t("h")]),_:1}),a(e,null,{default:l(()=>[t("=")]),_:1}),a(p,null,{default:l(()=>[a(e,{fence:"true"},{default:l(()=>[t("{")]),_:1}),a(b,{rowspacing:"0.16em",columnalign:"center center",columnspacing:"1em"},{default:l(()=>[a(v,null,{default:l(()=>[a(g,null,{default:l(()=>[a(_,{scriptlevel:"0",displaystyle:"false"},{default:l(()=>[a(m,null,{default:l(()=>[t("0")]),_:1})]),_:1})]),_:1}),a(g,null,{default:l(()=>[a(_,{scriptlevel:"0",displaystyle:"false"},{default:l(()=>[a(n,null,{default:l(()=>[t("P")]),_:1})]),_:1})]),_:1})]),_:1}),a(v,null,{default:l(()=>[a(g,null,{default:l(()=>[a(_,{scriptlevel:"0",displaystyle:"false"},{default:l(()=>[a(h,null,{default:l(()=>[a(n,null,{default:l(()=>[t("h")]),_:1}),a(p,null,{default:l(()=>[a(m,null,{default:l(()=>[t("1")]),_:1}),a(e,null,{default:l(()=>[t("−")]),_:1}),a(n,null,{default:l(()=>[t("p")]),_:1})]),_:1})]),_:1})]),_:1})]),_:1}),a(g,null,{default:l(()=>[a(_,{scriptlevel:"0",displaystyle:"false"},{default:l(()=>[a(p,null,{default:l(()=>[a(n,{mathvariant:"normal"},{default:l(()=>[t("o")]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("t")]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("h")]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("e")]),_:1}),a(n,{mathvariant:"normal"},{default:l(()=>[t("r")]),_:1})]),_:1})]),_:1})]),_:1})]),_:1})]),_:1})]),_:1})]),_:1}),a(r,{encoding:"application/x-tex"},{default:l(()=>[t(" h=\\left\\{\\begin{matrix}0&P\\\\ \\frac{h}{1-p}&\\mathrm{other}\\end{matrix}\\right. ")]),_:1})]),_:1})]),_:1})]),pa])])]),_:1})]),t(" 根据此模型的设计，其期望值保持不变，即$E[h'] = h $")]),ma])}const fa=k(F,[["render",ca]]);export{ga as __pageData,fa as default};
