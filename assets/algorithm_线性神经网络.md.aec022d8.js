import{_ as e,o as a,c as t,a as o}from"./chunks/framework.13d73f51.js";const _=JSON.parse('{"title":"线性神经网络","description":"","frontmatter":{"layout":"doc","title":"线性神经网络","createTime":"2023/3/24","preview":"我们从经典算法-线性神经网络开始，介绍神经网络的基础知识。 经典统计学习技术中的线性回归和softmax回归可以视为线性神经网络， 这些知识将为本书其他部分中更复杂的技术奠定基础。"},"headers":[],"relativePath":"algorithm/线性神经网络.md","lastUpdated":1679657738000}'),i={name:"algorithm/线性神经网络.md"},r=o('<h1 id="线性神经网络" tabindex="-1">线性神经网络 <a class="header-anchor" href="#线性神经网络" aria-label="Permalink to &quot;线性神经网络&quot;">​</a></h1><h2 id="线性回归" tabindex="-1">线性回归 <a class="header-anchor" href="#线性回归" aria-label="Permalink to &quot;线性回归&quot;">​</a></h2><blockquote><p><em>回归</em>（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法。</p></blockquote><h3 id="基本元素" tabindex="-1">基本元素 <a class="header-anchor" href="#基本元素" aria-label="Permalink to &quot;基本元素&quot;">​</a></h3><h4 id="线性模型" tabindex="-1">线性模型 <a class="header-anchor" href="#线性模型" aria-label="Permalink to &quot;线性模型&quot;">​</a></h4><p><img src="https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230324145628037.png" alt="image-20230324145628037"></p><blockquote><p>即使确信特征与标签的潜在关系是线性的， 我们也会加入一个噪声项来考虑观测误差带来的影响。</p><p>在开始寻找最好的<em>模型参数</em>（model parameters）w和b之前， 我们还需要两个东西： （1）一种模型质量的度量方式； （2）一种能够更新模型以提高模型预测质量的方法。</p></blockquote><h4 id="损失函数" tabindex="-1">损失函数 <a class="header-anchor" href="#损失函数" aria-label="Permalink to &quot;损失函数&quot;">​</a></h4><p><em>损失函数</em>（loss function）能够量化目标的<em>实际</em>值与<em>预测</em>值之间的差距。</p><p>为了度量模型在整个数据集上的质量，我们需计算在训练集n个样本上的损失均值（也等价于求和）。</p><p><img src="https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230324150109654.png" alt="image-20230324150109654"></p><h4 id="解析解" tabindex="-1">解析解 <a class="header-anchor" href="#解析解" aria-label="Permalink to &quot;解析解&quot;">​</a></h4><p>线性回归的解可以用一个公式简单地表达出来， 这类解叫作解析解（analytical solution）</p><blockquote><p>解析解可以进行很好的数学分析，但解析解对问题的限制很严格，导致它无法广泛应用在深度学习里。</p></blockquote><h4 id="随机梯度下降" tabindex="-1">随机梯度下降 <a class="header-anchor" href="#随机梯度下降" aria-label="Permalink to &quot;随机梯度下降&quot;">​</a></h4><p>**<em>梯度下降</em>（gradient descent）**这种方法几乎可以优化所有深度学习模型。 它通过不断地在损失函数递减的方向上更新参数来降低误差。</p><h4 id="单层神经网络" tabindex="-1">单层神经网络 <a class="header-anchor" href="#单层神经网络" aria-label="Permalink to &quot;单层神经网络&quot;">​</a></h4><p><img src="https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230324192345662.png" alt="image-20230324192345662"></p><p>由于模型重点在发生计算的地方，所以通常我们在计算层数时不考虑输入层。 也就是说， [图3.1.2]中神经网络的<em>层数</em>为1。</p><p>对于线性回归，每个输入都与每个输出（在本例中只有一个输出）相连， 我们将这种变换（ [图3.1.2]中的输出层） 称为<em>全连接层</em>（fully-connected layer）或称为<em>稠密层</em>（dense layer）。</p>',20),n=[r];function s(l,m,c,h,p,d){return a(),t("div",null,n)}const b=e(i,[["render",s]]);export{_ as __pageData,b as default};
