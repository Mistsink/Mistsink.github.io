---
title: MySQL45讲 - 小记
createTime: 2023/2/19
preview: MySQL原理相关的阅读笔记
---
# MySQL45讲 - 小记

> 时不时更 ...

## 基础架构

- 连接器
- 查询缓存

  > mysql8.0后已删除该模块
  >
- 分析器

  > 编译原理中的词法分析、语义分析，会构建AST，进行语义检查
  >
- 优化器

  > 优化查询计划：多表现于选择哪个索引、join时多表的查询顺序等
  >
- 执行器
- 存储引擎

## 日志系统

- Redo log

  > InnoDB特有
  >

  1. 存储结构是一个固定大小的循环队列，写满后需清理部分才能继续写
  2. 以 block 形式固定大小存储，在其中 boby 部分追加写内容，覆盖写
  3. 记录物化信息：某个数据页发生了什么变化（猜测应该使用了物化与逻辑的混合模式
- Binlog

  > mysql 的 server 层持有的，归档日志
  >

  1. 存储结构是一个可追加写的文件，无大小限制
  2. 记录逻辑信息：可理解为将 sql 语句记录下来了

两者间，一是 InnoDB 引擎所有，一是 mysql 层所有，为了保证事务提交后的两日志一致性，采用两阶段提交模型，只有在 redo、bin 都落盘后，事务才能 commit 成功。

> 两阶段提交：可用于跨系统间的数据一致性

## 事务

- 特性：原子性、一致性、隔离性、持久性
- 多事务同时执行的时候，可能会出现的问题：脏读、不可重复读、幻读
- 隔离级别：读未提交、读提交、可重复读、串行化

  1. 读未提交：一个事务还未提交，它所做的变更就可以被别的事务看到
  2. 读提交：一个事务提交之后，它所做的变更才可以被别的事务看到
  3. 可重复读：一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的
  4. 串行化：对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行
- 配置方法：启动参数transaction-isolation
- 事务隔离的实现：

  1. 读未提交、读提交：引入读写锁
  2. 可重复读：MVCC（多版本并发控制）
  3. 串行化：引入间隙锁或谓词锁等概念
- 回滚日志什么时候删除？

  > 系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。
  >
- 什么时候不需要了？

  > 当系统里么有比这个回滚日志更早的read-view的时候。
  >
- 为什么尽量不要使用长事务?

  > 长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。
  >
- 事务启动方式：

  1. 显式启动事务语句，begin或者start transaction,提交commit，回滚rollback；
  2. set autocommit=0，该命令会把这个线程的自动提交关掉。这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行commit或rollback或断开连接。

  建议使用 方法1

  > 如果考虑多一次交互问题，可以使用commit work and chain语法。在autocommit=1的情况下用begin显式启动事务，如果执行commit则提交事务。如果执行commit work and chain则提交事务并自动启动下一个事务。
  >

### 思考

系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？

> 在开发过程中，尽可能的减小事务范围，少用长事务，如果无法避免，保证逻辑日志空间足够用，并且支持动态日志空间增长。监控Innodb_trx表，发现长事务报警。

## 索引

1. 索引的作用：提高数据查询效率
2. 常见索引模型：哈希表、有序数组、搜索树
3. 哈希表：键 - 值(key - value)。
   1. 哈希思路：把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置
   2. 哈希冲突的处理办法：链表（各种解决算法都有，拉链、二次、线性等等，根据哈希存储的具体实现也有关）
   3. 哈希表适用场景：只有等值查询的场景
4. 有序数组：按顺序存储。
   1. 查询用二分法就可以快速查询，时间复杂度是：O(log(N))
   2. 有序数组查询效率高，更新效率低
   3. 有序数组的适用场景：静态存储引擎。
5. 二叉搜索树：每个节点的左儿子小于父节点，父节点又小于右儿子
   1. 查询时间复杂度O(log(N))，更新时间复杂度O(log(N))
   2. 数据库存储大多不适用二叉树，因为树高过高，会适用N叉树
6. InnoDB中的索引模型：B+Tree
7. 索引类型：主键索引、非主键索引
   1. 主键索引的叶子节点存的是整行的数据(聚簇索引)，非主键索引的叶子节点内容是主键的值(二级索引)
   2. 主键索引和普通索引的区别：主键索引只要搜索ID这个B+Tree即可拿到数据。普通索引先搜索索引拿到主键值，再到主键索引树搜索一次(回表)
8. 页分裂与页合并：
   一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做页分裂，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做数据页合并，合并的过程是分裂过程的逆过程。
9. 从性能和存储空间方面考量，自增主键往往是更合理的选择。

### 思考

对于下面例子中的InnoDB表T:

```sql
create table T(
  id int primary key, 
  k int not null, 
  name varchar(16),
  index (k))engine=InnoDB;
```

如果你要重建索引 k，你的两个SQL语句可以这么写：

```
alter table T drop index k;
alter table T add index(k);
```

如果你要重建主键索引，也可以这么写：

```
alter table T drop primary key;
alter table T add primary key(id);
```

对于上面这两个重建索引的作法，说出你的理解。如果有不合适的，为什么，更好的方法是什么？

> 重建索引k的做法是合理的，可以达到省空间的目的。但是，重建主键的过程不合理。不论是删除主键还是创建主键，都会将整个表重建。所以连着执行这两个语句的话，第一个语句就白做了。这两个语句，你可以用这个语句代替 ： alter table T engine=InnoDB。

1. 回表：回到主键索引树搜索的过程，称为回表

2. 覆盖索引：某索引已经覆盖了查询需求，称为覆盖索引，例如：select ID from T where k between 3 and 5（此时 ID 是主键索引，k 是普通索引，而普通索引 k 的叶子结点上的值就是 ID 值）

   - 在引擎内部使用覆盖索引在索引K上其实读了三个记录，R3~R5(对应的索引k上的记录项)，但对于MySQL的Server层来说，它就是找引擎拿到了两条记录，因此MySQL认为扫描行数是2

3. 最左前缀原则：B+Tree这种索引结构，可以利用索引的"最左前缀"来定位记录。只要满足最左前缀，就可以利用索引来加速检索。

   - 最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符

   - 联合索引的顺序安排：第一原则是：如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。

4. 索引下推：
   在MySQL5.6之前，只能从根据最左前缀查询到ID开始一个个回表。到主键索引上找出数据行，再对比字段值。
   MySQL5.6引入的索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

### 思考

实际上主键索引也是可以使用多个字段的。DBA小吕在入职新公司的时候，就发现自己接手维护的库里面，有这么一个表，表结构定义类似这样的：

```sql
CREATE TABLE `geek` (
  `a` int(11) NOT NULL,
  `b` int(11) NOT NULL,
  `c` int(11) NOT NULL,
  `d` int(11) NOT NULL,
  PRIMARY KEY (`a`,`b`),
  KEY `c` (`c`),
  KEY `ca` (`c`,`a`),
  KEY `cb` (`c`,`b`)
) ENGINE=InnoDB;
```

公司的同事告诉他说，由于历史原因，这个表需要a、b做联合主键，这个小吕理解了。

但是，学过本章内容的小吕又纳闷了，既然主键包含了a、b这两个字段，那意味着单独在字段c上创建一个索引，就已经包含了三个字段了呀，为什么要创建“ca”“cb”这两个索引？

同事告诉他，是因为他们的业务里面有这样的两种语句：

```
select * from geek where c=N order by a limit 1;
select * from geek where c=N order by b limit 1;
```

我给你的问题是，这位同事的解释对吗，为了这两个查询模式，这两个索引是否都是必须的？为什么呢？

> 表记录
>
> | a    | b    | c    | d    |
> | ---- | ---- | ---- | ---- |
> | 1    | 2    | 3    | d    |
> | 1    | 3    | 2    | d    |
> | 1    | 4    | 3    | d    |
> | 2    | 1    | 3    | d    |
> | 2    | 2    | 2    | d    |
> | 2    | 3    | 4    | d    |
>
>
> 主键 a，b的聚簇索引组织顺序相当于 order by a,b ，也就是先按a排序，再按b排序，c无序。
>
> 索引 ca 的组织是先按c排序，再按a排序，同时记录主键
>
> | C    | a    | b（注意这里不是ab，而是只有b） |
> | ---- | ---- | ------------------------------ |
> | 2    | 1    | 3                              |
> | 2    | 2    | 2                              |
> | 3    | 1    | 2                              |
> | 3    | 1    | 4                              |
> | 3    | 2    | 1                              |
> | 4    | 2    | 3                              |
>
> 这个跟索引c的数据是一模一样的。
>
> 索引 cb 的组织是先按c排序，在按b排序，同时记录主键
>
> | c    | b    | a    |
> | ---- | ---- | ---- |
> | 2    | 2    | 2    |
> | 2    | 3    | 2    |
> | 3    | 1    | 2    |
> | 3    | 2    | 1    |
> | 3    | 4    | 1    |
> | 4    | 3    | 2    |
>
> **所以，结论是ca可以去掉，cb需要保留。**

## 锁

> 根据加锁范围：MySQL里面的锁可以分为：全局锁、表级锁、行级锁

1. 全局锁：

   - 对整个数据库实例加锁。
   - MySQL提供加全局读锁的方法：Flush tables with read lock(FTWRL)
     - 这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。
     - 使用场景：全库逻辑备份。
     - 风险：
       1. 如果在主库备份，在备份期间不能更新，业务停摆
       2. 如果在从库备份，备份期间不能执行主库同步的`binlog`，导致主从延迟
   - 官方自带的逻辑备份工具mysqldump，当mysqldump使用参数--single-transaction的时候，会启动一个事务，确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。
   - 一致性读是好，但是前提是引擎要支持这个隔离级别。

   - 如果要全库只读，为什么不使用`set global readonly=true`的方式？

     > 1. 在有些系统中，readonly的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。
     > 2. 在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。

2. 表级锁:

   - MySQL里面表级锁有两种，一种是表锁，一种是元数据锁(meta data lock,MDL)

     - 表锁的语法是:`lock tables ... read/write`
       **可以用`unlock tables`主动释放锁，也可以在客户端断开的时候自动释放。**lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

       > 对于`InnoDB`这种支持行锁的引擎，一般不使用`lock tables`命令来控制并发，毕竟锁住整个表的影响面还是太大。

     - `MDL`：不需要显式使用，在访问一个表的时候会被自动加上。

       - MDL的作用：保证读写的正确性。

       - 在对一个表做增删改查操作的时候，加MDL读锁；**当要对表做结构变更操作的时候，加MDL写锁。**
       - 读锁之间不互斥。读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。
       - **MDL 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。**

### 思考

备份一般都会在备库上执行，你在用–single-transaction方法做逻辑备份的过程中，如果主库上的一个小表做了一个DDL，比如给一个表上加了一列。这时候，从备库上会看到什么现象呢？

> 假设这个DDL是针对表t1的， 这里我把备份过程中几个关键的语句列出来：
>
> ```sql
> Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
> Q2:START TRANSACTION  WITH CONSISTENT SNAPSHOT；
> /* other tables */
> Q3:SAVEPOINT sp;
> /* 时刻 1 */
> Q4:show create table `t1`;
> /* 时刻 2 */
> Q5:SELECT * FROM `t1`;
> /* 时刻 3 */
> Q6:ROLLBACK TO SAVEPOINT sp;
> /* 时刻 4 */
> /* other tables */
> ```
>
> 在备份开始的时候，为了确保RR（可重复读）隔离级别，再设置一次RR隔离级别(Q1);
>
> 启动事务，这里用 `WITH CONSISTENT SNAPSHOT`确保这个语句执行完就可以得到一个一致性视图（Q2)；
>
> 设置一个保存点，这个很重要（Q3）；
>
> `show create` 是为了拿到表结构(Q4)，然后正式导数据 （Q5），回滚到`SAVEPOINT sp`，在这里的作用是释放 t1的MDL锁 （Q6。当然这部分属于“超纲”，上文正文里面都没提到。
>
> DDL从主库传过来的时间按照效果不同，我打了四个时刻。题目设定为小表，我们假定到达后，如果开始执行，则很快能够执行完成。
>
> 参考答案如下：
>
> 1. 如果在Q4语句执行之前到达，现象：没有影响，备份拿到的是DDL后的表结构。
> 2. 如果在“时刻 2”到达，则表结构被改过，Q5执行的时候，报 `Table definition has changed, please retry transaction`，现象：mysqldump终止；
> 3. 如果在“时刻2”和“时刻3”之间到达，mysqldump占着t1的MDL读锁，binlog被阻塞，现象：主从延迟，直到Q6执行完成。
> 4. 从“时刻4”开始，mysqldump释放了MDL读锁，现象：没有影响，备份拿到的是DDL前的表结构。

3. 行级锁：MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。
   - 两阶段锁：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放， 而是要等到事务结束时才释放。
   - 如何安排正确的事务语句：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
   - 死锁：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态。
     解决方案：
     1. 通过参数 innodb_lock_wait_timeout 根据实际业务场景来设置超时时间，InnoDB引擎默认值是50s。
     2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑（默认是开启状态）。
   - 如何解决热点行更新导致的性能问题？
     1. 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用
     2. 控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。
     3. 将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。
   - **Innodb行级锁是通过锁索引记录实现的**，如果更新的列没建索引是会锁住整个表的。

### 思考

如果你要删除一个表里面的前10000行数据，有以下三种方法可以做到：

- 第一种，直接执行delete from T limit 10000;
- 第二种，在一个连接中循环执行20次 delete from T limit 500;
- 第三种，在20个连接中同时执行delete from T limit 500。

你会选择哪一种方法呢？为什么呢？

> 在一个连接中循环执行20次 delete from T limit 500。
>
> 确实是这样的，第二种方式是相对较好的。
>
> 第一种方式（即：直接执行delete from T limit 10000）里面，单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。
>
> 第三种方式（即：在20个连接中同时执行delete from T limit 500），会人为造成锁冲突。

## 可重复读隔离级别

1. `Innodb`支持`RC`和`RR`隔离级别实现是用的`一致性视图(consistent read view)`

2. 事务在启动时会拍一个快照，这个**快照是基于整个库的.**
   - 基于整个库的意思就是说一个事务内，整个库的修改对于该事务都是不可见的（对于快照读的情况）
   - 如果在事务内`select t`表，另外的事务执行了`DDL t`表,根据发生时间,要嘛锁住要嘛报错

3. 事务是如何实现的MVCC呢?

   1. 每个事务都有一个事务ID，叫做`transaction id（严格递增）`

   2. **事务在启动时，找到已提交的最大事务`ID`记为`up_limit_id`。**

   3. 事务在更新一条语句时,比如id=1改为了id=2.会把id=1和该行之前的`row trx_id`写到`undo log`里，并且在数据页上把id的值改为2,并且把修改这条语句的`transaction id`记在该行行头

   4. 再定一个规矩,一个事务要查看一条数据时,必须先用该事务的`up_limit_id`与该行的`transaction id`做比对:
      如果`up_limit_id >= transaction id`,那么可以看.如果`up_limit_id < transaction id`，则只能去`undo log`里去取。去`undo log`查找数据的时候,也需要做比对，必须`up_limit_id > transaction id`，才返回数据

      ![image-20230221163908395](https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230221163908395.png)

4. 什么是当前读，由于当前读都是先读后写，只能读当前的值，所以为当前读。
   会更新事务内的`up_limit_id`为该事务的`transaction id`。
   **就是读当前事务可以看见的值。**

5. 为什么`RR`能实现可重复读而`RC`不能，分两种情况：
   1. 快照读的情况下，`RR`不能更新事务内的`up_limit_id`，而`RC`每次会把`up_limit_id`更新为快照读之前最新已提交事务的`transaction id`，则`RC`不能可重复读
   2. 当前读的情况下，`RR`是利用`record lock + gap lock`来实现的，而`RC`没有`gap`，所以`RC`不能可重复读

### 思考

用下面的表结构和初始化语句作为试验环境，事务隔离级别是可重复读。现在，我要把所有“字段c和id值相等的行”的c值清零，但是却发现了一个“诡异”的、改不掉的情况。请你构造出这种情况，并说明其原理。

```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;

insert into t(id, c) values(1,1),(2,2),(3,3),(4,4);
```

![img](https://static001.geekbang.org/resource/image/9b/0b/9b8fe7cf88c9ba40dc12e93e36c3060b.png)
复现出来以后，请你再思考一下，在实际的业务开发中有没有可能碰到这种情况？你的应用代码会不会掉进这个“坑”里，你又是怎么解决的呢？

![img](https://static001.geekbang.org/resource/image/be/ae/be7a4d8af04cdf93aaa11108933559ae.png)
这样，`session A`看到的就是截图的效果了。

还有另外一种场景:

![img](https://static001.geekbang.org/resource/image/e2/fa/e24a0689571337959138d787c408defa.png)

这个操作序列跑出来，`session A`看的内容也是能够复现截图的效果的。这个`session B`启动的事务比`A`要早，因为可见行规则里还有一个“活跃事务的判断”。（可见`15-445`中的内容`MVCC 及 Serializable`相关内容）
