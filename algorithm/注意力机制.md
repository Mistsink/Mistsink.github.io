---
layout: doc
title: 注意力机制
createTime: 2023/4/8
preview: 
---

# 注意力机制

### 注意力提示

#### 查询、键、值

自主性的与非自主性的注意力提示解释了人类的注意力的方式， 下面来看看如何通过这两种注意力提示， 用神经网络来设计注意力机制的框架，

首先，考虑一个相对简单的状况， 即只使用非自主性提示。 要想将选择偏向于感官输入， 则可以简单地使用参数化的全连接层， 甚至是非参数化的最大汇聚层或平均汇聚层。

> 因此，“是否包含自主性提示”将注意力机制与全连接层或汇聚层区别开来。

在注意力机制的背景下，自主性提示被称为*查询*（query）。 给定任何查询，注意力机制通过*注意力汇聚*（attention pooling） 将选择引导至*感官输入*（sensory inputs，例如中间特征表示）。在注意力机制中，这些感官输入被称为*值*（value）。

![image-20230407164126905](https://raw.githubusercontent.com/Mistsink/image-host/main/img/image-20230407164126905.png)

平均汇聚层可以被视为输入的加权平均值， 其中各输入的权重是一样的。 实际上，注意力汇聚得到的是加权平均的总和值， 其中权重是在给定的查询和不同的键之间计算得出的。

> "注意力汇聚是一种将多个输入按照不同的权重进行加权平均的方法。具体来说，对于每个输入，都有一个与之对应的权重值，这个权重值反映了这个输入在输出中所占的重要程度。最终，对于所有的输入，这些权重值会被用来计算它们在输出中的加权平均总和值，得到最终的汇聚结果。因此，可以说注意力汇聚是通过权重来调节每个输入对输出的贡献度，从而达到更加灵活、精准的信息提取的方式。"
>
> 这里的多个输入可以理解为多个 `key`，每个`查询`到来的时候，会计算与每个`key`的关联度，赋予每个`key`不一样的权重，来控制每个`key`对最终输出的贡献程度。宏观上就可以理解为你的注意力侧重于哪些`key`，那么哪些`key`的权重就会大，别的`key`权重就会小。

## 注意力汇聚：Nadaraya-Watson核回归

注意力机制的主要成分 [图10.1.3](https://zh.d2l.ai/chapter_attention-mechanisms/attention-cues.html#fig-qkv)： 查询（自主提示）和键（非自主提示）之间的交互形成了注意力汇聚； 注意力汇聚有选择地聚合了值（感官输入）以生成最终的输出。